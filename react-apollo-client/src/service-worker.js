/* eslint-disable no-restricted-globals */

// This service worker can be customized!
// See https://developers.google.com/web/tools/workbox/modules
// for the list of available Workbox modules, or add any other
// code you'd like.
// You can also remove this file if you'd prefer not to use a
// service worker, and the Workbox build step will be skipped.
import { clientsClaim } from 'workbox-core';
import { ExpirationPlugin } from 'workbox-expiration';
import { precacheAndRoute, createHandlerBoundToURL } from 'workbox-precaching';
import { registerRoute } from 'workbox-routing';
import { StaleWhileRevalidate } from 'workbox-strategies';
import * as CryptoJS from 'crypto-js';
import { get, set } from 'idb-keyval';
import * as idbKeyval from 'idb-keyval';

clientsClaim();
sendOfflinePostRequestsToServer();

// navigator.connection.onchange = (e) => {
//     if (navigator.onLine) {
//         sendOfflinePostRequestsToServer();
//     }
// };
// THE ABOVE CODE IS A LOT LESS RESOURCE INTENSIVE BUT THE BELOW CODE PROVIDES A BETTER USER EXPERIENCE BECAUSE IT AUTOMATICALLY SEND OUT THE REQUEST AGAIN AND AGAIN IF IT FAILS. THE CODE ABOVE WOULD ONLY SEND OUT A REQUEST WHEN USER GOES OFFLINE AND THEN COME BACK ONLINE AGAIN
setInterval(() => {
    sendOfflinePostRequestsToServer();
}, 2000);

// Precache all of the assets generated by your build process.
// Their URLs are injected into the manifest variable below.
// This variable must be present somewhere in your service worker file,
// even if you decide not to use precaching. See https://cra.link/PWA
precacheAndRoute(self.__WB_MANIFEST);

// Set up App Shell-style routing, so that all navigation requests
// are fulfilled with your index.html shell. Learn more at
// https://developers.google.com/web/fundamentals/architecture/app-shell
const fileExtensionRegexp = new RegExp('/[^/?]+\\.[^/]+$');
registerRoute(
    // Return false to exempt requests from being fulfilled by index.html.
    ({ request, url }) => {
        // If this isn't a navigation, skip.
        if (request.mode !== 'navigate') {
            return false;
        } // If this is a URL that starts with /_, skip.

        if (url.pathname.startsWith('/_')) {
            return false;
        } // If this looks like a URL for a resource, because it contains // a file extension, skip.

        if (url.pathname.match(fileExtensionRegexp)) {
            return false;
        } // Return true to signal that we want to use the handler.

        return true;
    },
    createHandlerBoundToURL(process.env.PUBLIC_URL + '/index.html')
);

// An example runtime caching route for requests that aren't handled by the
// precache, in this case same-origin .png requests like those from in public/
registerRoute(
    // Add in any other file extensions or routing criteria as needed.
    ({ url }) =>
        url.origin === self.location.origin && url.pathname.endsWith('.png'), // Customize this strategy as needed, e.g., by changing to CacheFirst.
    new StaleWhileRevalidate({
        cacheName: 'images',
        plugins: [
            // Ensure that once this runtime cache reaches a maximum size the
            // least-recently used images are removed.
            new ExpirationPlugin({ maxEntries: 50 }),
        ],
    })
);

// This allows the web app to trigger skipWaiting via
// registration.waiting.postMessage({type: 'SKIP_WAITING'})
self.addEventListener('message', (event) => {
    if (event.data && event.data.type === 'SKIP_WAITING') {
        self.skipWaiting();
    }
});

// ==========================================================================================================================================
const store = new idbKeyval.createStore('GraphQL-Cache', 'PostResponses');

self.addEventListener('fetch', async (event) => {
    if (event.request.method === 'POST') {
        // Respond with cached data and update from network in the background.
        event.respondWith(staleWhileRevalidate(event));
    }
});

// This function implements the stale-while-revalidate cache strategy. It first tries to get a cached response using the getCache function. If there is a cached response, it returns that response immediately. If there is no cached response, it sends the request to the server using the fetch API and caches the response using the setCache function. It then returns the response to the client.

// The Request object is a stream and can only be consumed once. When you use the fetch() method or the event.respondWith() method, the Request object is consumed by the browser and cannot be used again. If you need to use the same Request object for multiple purposes, such as modifying the headers or retrying a failed request, you should create a clone of the original Request object using event.request.clone(). The same goes for response object

// If there is an error and the user is offline and if the "operationName" is "AddBook", then we extract the auth header, req url and the string representation of the actual body of the request using ".text()", which return a promise and when the promise resolves, we get back a response object containing the acutal string inside the callback function. We then pass, the req url, authHeader and the payload to "saveIntoIndexDb"
async function staleWhileRevalidate(event) {
    let cachedResponse = await getCache(event.request.clone());

    let fetchPromise = fetch(event.request.clone())
        .then((response) => {
            setCache(event.request.clone(), response.clone());
            return response;
        })
        .catch(async (err) => {
            if (!navigator.onLine) {
                let requestCopy = event.request.clone();
                let body = await requestCopy.json();

                if (body.operationName === 'AddBook') {
                    var authHeader = event.request.headers.get('Authorization');
                    var reqUrl = event.request.url;
                    // Promise.resolve(event.request.text()).then((payload) => {
                    //     //save offline requests to indexed db
                    //     saveIntoIndexedDb(reqUrl, authHeader, payload);
                    // });
                    // SIMPLIFIED THE ABOVE CODE TO BELOW CODE
                    event.request.text().then((payload) => {
                        //save offline requests to indexed db
                        saveIntoIndexedDb(reqUrl, authHeader, payload);
                    });
                }
            }
        });
    return cachedResponse ? Promise.resolve(cachedResponse) : fetchPromise;
}

// The reason for parsing and then stringifying the payload is to ensure that the data stored in the IndexedDB is a string. The IndexedDB API only allows storing data in the form of key-value pairs, where both the key and value are strings. Therefore, if the payload parameter is not already a string, it needs to be parsed into a JavaScript object using JSON.parse(). Then, it needs to be converted back into a string using JSON.stringify() to store it in the IndexedDB.

// Also, parsing the payload with JSON.parse() ensures that the payload parameter is a valid JSON string, so that it can be stored and retrieved from the IndexedDB as a JSON object. This is important because if the payload is not a valid JSON string, it cannot be converted into a JavaScript object, and therefore cannot be stored in the IndexedDB.

// We are then opening an IndexedDB database named "GraphQL-Post-Requests" using the indexedDB.open() method. If the database already exists, it will be opened, otherwise a new database will be created. The open() method returns a request object that can be used to handle events related to opening the database.

// Once the database is successfully opened, the onsuccess event is fired, which triggers the event handler function that is defined as follows:

// The event parameter is an event object containing information about the success event, such as the result of the request.
// The event.target property returns the request object that was used to open the database.
// The event.target.result property returns the database object that was opened.
// The event handler function then creates a new transaction using db.transaction() method. In IndexedDB, all database operations are done within transactions. A transaction is a way to group one or more operations together and ensure that they are all completed successfully or not at all. A transaction can be read-only or read-write, depending on whether it needs to modify the data or not. The transaction is created with the 'postrequest' object store, and the mode is set to 'readwrite', which means that this transaction is intended to write to the database.

// Next, the objectStore() method is called on the transaction object to obtain a reference to the "postrequest" object store. This object store represents a collection of objects that will be stored in the database.

// Finally, the add() method is called on the object store to add the myRequest object to the object store. This will store the request data in the IndexedDB database under a unique key that is generated by the database system.
function saveIntoIndexedDb(url, authHeader, payload) {
    var myRequest = {};
    let jsonPayLoad = JSON.parse(payload);
    myRequest.url = url;
    myRequest.authHeader = authHeader;
    myRequest.payload = JSON.stringify(jsonPayLoad);
    var request = indexedDB.open('GraphQL-Post-Requests');
    request.onsuccess = function (event) {
        var db = event.target.result;
        var tx = db.transaction('postrequest', 'readwrite');
        var store = tx.objectStore('postrequest');
        store.add(myRequest);
    };
}

// We first opens the IndexedDB database, with the name GraphQL-Post-Requests. Then we define an onsuccess callback for the request to the IndexedDB, which will be called once the database is successfully opened. This callback then starts a new transaction on the postrequest object store with the 'readwrite' mode, and retrieves all the records from the store using the getAll() method. Then we define an onsuccess callback for the request to read all the records, which will be called once we recieve all the records from the store. Inside the callback we make sure if there are any records in the store and then access a list of objects which contains the record data using ".result".

// Then we take the first record and create a fetch request and send it to the "sendFetchRequestsToServer" along with the url, authHeader, payload and the rest of the records. Once we get back a response from the "sendFetchRequestsToServer" function we then use a for loop to iterate over the records in the store to delete them one by one. 
async function sendOfflinePostRequestsToServer() {
    var request = indexedDB.open('GraphQL-Post-Requests');
    request.onsuccess = function (event) {
        var db = event.target.result;
        var tx = db.transaction('postrequest', 'readwrite');
        var store = tx.objectStore('postrequest');
        var allRecords = store.getAll();
        allRecords.onsuccess = function () {
            if (allRecords.result && allRecords.result.length > 0) {
                // "allRecords.result" returns a list of object
                var records = allRecords.result;
                var resp = sendFetchRequestsToServer(
                    fetch(records[0].url, {
                        method: 'post',
                        headers: {
                            Accept: 'application/json',
                            'Content-Type': 'application/json',
                            Authorization: records[0].authHeader,
                        },
                        body: records[0].payload,
                    }),
                    records[0].url,
                    records[0].authHeader,
                    records[0].payload,
                    records.slice(1)
                );

                for (var i = 0; i < allRecords.result.length; i++)
                    store.delete(allRecords.result[i].id);
            }
        };
    };
    request.onupgradeneeded = function (event) {
        var db = event.target.result;
        db.onerror = function (event) {
            console.log("Why didn't you allow my web app to use IndexedDB?!");
        };

        var objectStore;
        if (!db.objectStoreNames.contains('postrequest')) {
            objectStore = db.createObjectStore('postrequest', {
                keyPath: 'id',
                autoIncrement: true,
            });
        } else {
            objectStore = db.objectStoreNames.get('postrequest');
        }
    };
}

// We recieve a fetch request, url of the fetch request, auth header, payload of the request and the rest of the records inside the store in indexedDB. Then we create a promise on the fetch request, such that when it resolves the response is available inside the call back. Once we get a response we then call the "sendFetchRequestsToServer" function recursively with the first record in the record array provided to the function. The first record inside this array would be actually the second record in the actual store because we had used "record.slice(1)" inside "sendOfflinePostRequestsToServer" when "sendFetchRequestToServer" was called for the first time. Next time the function is called then the first record would actually be the third record in the store because we are calling "records.slice(1)" inside the rescursive call.

// If an error occurs we save the request back to the indexedDB and the next time "sendOfflinePostRequestsToServer" is called then the request which had failed would again be retried
async function sendFetchRequestsToServer(
    data,
    reqUrl,
    authHeader,
    payload,
    records
) {
    let promise = Promise.resolve(data)
        .then((response) => {
            console.log('Successfully sent request to server');
            if (records.length != 0) {
                sendFetchRequestsToServer(
                    fetch(records[0].url, {
                        method: 'post',
                        headers: {
                            Accept: 'application/json',
                            'Content-Type': 'application/json',
                            Authorization: records[0].authHeader,
                        },
                        body: records[0].payload,
                    }),
                    records[0].url,
                    records[0].authHeader,
                    records[0].payload,
                    records.slice(1)
                );
            }
            return true;
        })
        .catch((e) => {
            //fetch fails only in case of network error. Fetch is successful in case of any response code
            console.log('Exception while sending post request to server' + e);
            saveIntoIndexedDb(reqUrl, authHeader, payload);
        });
}

// This code is about taking a response from a server and converting it into a plain JavaScript object(serialization) that can be easily used by a program.

// The function is called serializeResponse and it takes in a response object as its parameter. The response object contains information about the response that the server sent back after the program requested something from it.

// Now, let's look at the code inside the function.

// First, the code creates an empty object called serializedHeaders to store the headers from the server's response. Headers are pieces of information that tell us more about the response from the server. For example, they can tell us what type of data the response is in, or how big the response is.

// The code then goes through all the headers in the response object and adds them to the serializedHeaders object that we just created. This makes it easier to work with the headers in the program.
// Let's say that the response object contains the following headers:

// Content-Type: application/json
// Cache-Control: no-cache
// Server: Apache/2.4.10 (Unix)

// When the code for (var entry of response.headers.entries()) runs, response.headers.entries() creates an iterator that contains the headers in the response object.

// The first time the loop runs, "entry" will contain the key-value pair ["Content-Type", "application/json"]. The loop then assigns serializedHeaders["Content-Type"] = "application/json", which adds a key-value pair to the serializedHeaders object that looks like this:

// Next, the code creates another object called serialized and adds some information to it. This includes the serializedHeaders that we just created, as well as the status and statusText of the response. The status is a number that tells us whether the response was successful or not, and the statusText is a message that goes along with the status.

// Finally, the code adds the body of the response to the serialized object. The body is the actual data that the program requested from the server. The code uses the await keyword to wait for getting the JSON data before adding it to the serialized object. JSON is a way of representing data in a way that's easy for computers to work with.

// Finally, the code returns the serialized object, which contains all the information that we extracted from the response object.

// That's it! The serializeResponse function takes a response from the server and converts it into a plain JavaScript object that can be easily used by a program.
async function serializeResponse(response) {
    let serializedHeaders = {};

    for (var entry of response.headers.entries()) {
        serializedHeaders[entry[0]] = entry[1];
    }
    let serialized = {
        headers: serializedHeaders,
        status: response.status,
        statusText: response.statusText,
    };

    serialized.body = await response.json();
    return serialized;
}

// This code defines an asynchronous function setCache that takes in two parameters: a request object and a response object. The purpose of this function is to cache the response of an HTTP request so that subsequent requests can be served faster.

// Here's how it works:

// The function first waits for the request body to be parsed into a JavaScript object using the request.json() method. The parsed object is stored in the body variable.

// The function then generates a unique identifier for the request based on the query string of the request body. This is done using the CryptoJS.MD5() method, which generates an MD5 hash of the query string. The hash is converted to a string using the .toString() method and stored in the id variable.

// The function creates a new object entry that contains the query string, the serialized response object (which is obtained by calling the serializeResponse() function on the response object), and the current timestamp.

// Finally, the entry object is stored in the cache using the set() method. The set() method takes in three parameters: the id of the cache entry, the entry object to be stored in the cache, and the store where the cache is stored.
async function setCache(request, response) {
    let body = await request.json();
    let id = CryptoJS.MD5(body.query).toString();

    var entry = {
        query: body.query,
        response: await serializeResponse(response),
        timestamp: Date.now(),
    };
    set(id, entry, store);
}

// This is an async function called getCache that takes in a request parameter. The function tries to retrieve data from a cache based on the contents of the request.

// The function first tries to parse the JSON body of the request using await request.json(). If the request is an "AddBook" operation, it logs a message and returns null.

// If the request is not an "AddBook" operation, it generates an ID based on the query string using the CryptoJS library. The function then attempts to retrieve the cached data using the generated ID and a store object.

// If the cached data is not found, the function returns null.

//  If the cached data is found, the function checks the cache max age, by first getting the Cache-Control header(eg- Cache-Control: max-age=3600) from the request object using request.headers.get('Cache-Control'). If this header exists, it extracts the maximum age value by splitting the string at the equals sign using cacheControl.split('=')[1], then parses it as an integer using parseInt().

// If the Cache-Control header is not present, or if there is an error in parsing the maximum age value, the code sets the maximum age to 3600 seconds (1 hour) by default.

// Next, the code checks if the difference between the current time and the cached data timestamp is greater than the maximum age multiplied by 1000 (to convert seconds to milliseconds). If this is true, it means the cached data has expired, and the code logs a message saying so before returning null.

// If the cached data is still valid, the code logs a message saying it is loading the response from the cache. It then creates a new Response object with the cached data and returns it using new Response(JSON.stringify(data.response.body), data.response). This converts the cached response body to a JSON string and includes the original response object as metadata. The reason for returning a new Response object instead of the cached response directly is to ensure that the response object conforms to the expected interface for responses in the fetch API.

// The fetch API expects a response object to have certain properties, such as status, headers, and body. These properties are used by the client to parse and process the response data. By constructing a new Response object using the data from the cache, we can ensure that the response object we return conforms to the expected interface.

// If we were to simply return the cached response directly, there is a risk that it might not have all of the necessary properties or be formatted correctly, which could cause issues for the client when processing the response. By constructing a new Response object with the correct format and properties, we can ensure that the response will be handled correctly by the client.
async function getCache(request) {
    let data;
    try {
        let body = await request.json();
        if (body.operationName === 'AddBook') {
            console.log(
                'Add book request encountered returning null from cache'
            );
            return null;
        }
        let id = CryptoJS.MD5(body.query).toString();
        data = await get(id, store);
        if (!data) return null;

        let cacheControl = request.headers.get('Cache-Control');
        let maxAge = cacheControl ? parseInt(cacheControl.split('=')[1]) : 3600;
        if (Date.now() - data.timestamp > maxAge * 1000) {
            console.log(`Cache expired. Load from API endpoint.`);
            return null;
        }

        console.log(`Load response from cache.`);
        return new Response(JSON.stringify(data.response.body), data.response);
    } catch (err) {
        return null;
    }
}

//===============================================================
